{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Project : Enhancing Nucleus Segmentation and 3D Reconstruction Using Super-Resolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Members:\n",
    "### Rita Sulaiman – Student ID: 2210765051\n",
    "### Zeynep Yıldız – Student ID: 2210765033\n",
    "### Zharasbek Bimagambetov – Student ID: 2210356185\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU belleği temizlendi.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Kullanılmayan bellekleri temizle\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Zorla kullanılmayan memory'yi bırak\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "print(\"GPU belleği temizlendi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Image Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistopathologySRDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform_hr, transform_lr):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = [f for f in os.listdir(image_dir) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "        self.transform_hr = transform_hr\n",
    "        self.transform_lr = transform_lr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        hr = self.transform_hr(img)\n",
    "        lr = self.transform_lr(img)\n",
    "        return lr, hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_hr = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_lr = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  \n",
    "    transforms.Resize((512, 512)),  # back upsample\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs, device, save_path=\"model_epoch\"):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for lr, hr in tqdm(dataloader):\n",
    "            lr, hr = lr.to(device), hr.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            sr = model(lr)\n",
    "            loss = criterion(sr, hr)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            del sr, loss, lr, hr\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(sr, hr):\n",
    "    mse = F.mse_loss(sr, hr)\n",
    "    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "    return psnr.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 84/84 [02:00<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████▎            | 71/84 [01:19<00:14,  1.08s/it]"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = HistopathologySRDataset(image_dir='all tissue img', transform_hr=transform_hr, transform_lr=transform_lr)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "model = SRCNN().to(device)\n",
    "criterion = nn.L1Loss()  # replace MSELoss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=50, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def show_sr_results(model, dataset, device, index=0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Verisetinden bir örnek al\n",
    "        lr, hr = dataset[index]\n",
    "        lr = lr.unsqueeze(0).to(device)\n",
    "        sr = model(lr).cpu().squeeze(0)\n",
    "\n",
    "        # Tensorları görüntüye çevir\n",
    "        lr_img = TF.to_pil_image(lr.squeeze(0).cpu())\n",
    "        hr_img = TF.to_pil_image(hr.cpu())\n",
    "        sr_img = TF.to_pil_image(torch.clamp(sr, 0, 1))  # clamp önemli!\n",
    "\n",
    "        # Görüntüleri yan yana göster\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Low-Res (Upsampled)\")\n",
    "        plt.imshow(lr_img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(\"Super-Res (SRCNN Output)\")\n",
    "        plt.imshow(sr_img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"High-Res (Ground Truth)\")\n",
    "        plt.imshow(hr_img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()  # RAM’i temizle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_sr_results(model, dataset, device, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "def evaluate_sr_quality(model, dataset, device, index=0):\n",
    "    \"\"\"\n",
    "    Verilen model ve dataset ile belirtilen index'teki görüntü için\n",
    "    PSNR ve SSIM değerlerini hesaplar ve görüntüleri gösterir.\n",
    "    \"\"\"\n",
    "    model.eval()  # Modeli değerlendirme moduna al\n",
    "    with torch.no_grad():\n",
    "        # Dataset'ten LR ve HR görüntüyü al\n",
    "        lr, hr = dataset[index]\n",
    "        lr = lr.unsqueeze(0).to(device)     # Model inputu için batch dimension ekle\n",
    "        hr = hr.unsqueeze(0).to(device)\n",
    "\n",
    "        # Modelden süper çözünürlük çıktısını al\n",
    "        sr = model(lr).clamp(0.0, 1.0)      # Çıktıyı 0–1 arasına kırp\n",
    "\n",
    "        # PSNR hesapla (pytorch → numpy çevirip kullanıyoruz)\n",
    "        sr_np = sr.squeeze().cpu().permute(1, 2, 0).numpy()  # CxHxW → HxWxC\n",
    "        hr_np = hr.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "        psnr = peak_signal_noise_ratio(hr_np, sr_np, data_range=1.0)\n",
    "\n",
    "        # SSIM hesapla (renkli olduğu için multichannel=True)\n",
    "        ssim = structural_similarity(hr_np, sr_np, data_range=1.0, channel_axis=2)\n",
    "\n",
    "        # Sonuçları yazdır\n",
    "        print(f\" PSNR: {psnr:.2f} dB\")\n",
    "        print(f\" SSIM: {ssim:.4f}\")\n",
    "\n",
    "        # Karşılaştırmalı görsel göster\n",
    "\n",
    "        lr_img = TF.to_pil_image(lr.squeeze(0).cpu())\n",
    "        hr_img = TF.to_pil_image(hr.squeeze(0).cpu())\n",
    "        sr_img = TF.to_pil_image(sr.squeeze(0).cpu())\n",
    "\n",
    "\n",
    "        print(\"Görüntü boyutu:\", sr_img.size)  # (yükseklik, genişlik, kanal sayısı)\n",
    "        \n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Low-Res (Upsampled)\")\n",
    "        plt.imshow(lr_img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"Super-Res\\nPSNR: {psnr:.2f} dB, SSIM: {ssim:.4f}\")\n",
    "        plt.imshow(sr_img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"High-Res (Ground Truth)\")\n",
    "        plt.imshow(hr_img)\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()  # RAM’i temizle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_sr_quality(model, dataset, device, index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_sr_quality(model, dataset, device, index=5)\n",
    "evaluate_sr_quality(model, dataset, device, index=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"srcnn_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "cmp_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
