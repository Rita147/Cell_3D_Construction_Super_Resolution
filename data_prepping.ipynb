{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d775395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rita\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\rita\\.cache\\kagglehub\\datasets\\ipateam\\nuinsseg\\versions\\5\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# For splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ipateam/nuinsseg\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b713b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root where each organ folder lives, containing subfolders:\n",
    "#  - 'tissue images'\n",
    "#  - 'mask binary'\n",
    "#  - 'distance maps'\n",
    "#  - 'label masks modify'\n",
    "#  - 'vague areas/mask binary'\n",
    "from pathlib import Path\n",
    "\n",
    "# ✅ Root folder that contains the organ folders (NuInsSeg has organ-based structure)\n",
    "RAW_ROOT = Path(r\"C:\\Users\\rita\\.cache\\kagglehub\\datasets\\ipateam\\nuinsseg\\versions\\5\")\n",
    "\n",
    "# ✅ Where you want to store processed/resized/split data\n",
    "OUT_ROOT = Path(\"data\")  # you can change this to e.g., \"processed_nuinsseg\"\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# ✅ Image size for all images and masks\n",
    "TARGET_SIZE = (256, 256)\n",
    "\n",
    "# ✅ Split ratios\n",
    "test_frac = 0.10    # 10% of all = test\n",
    "val_frac = 0.10     # 10% of the rest = val\n",
    "random_seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9558f5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory scaffold created under data\n"
     ]
    }
   ],
   "source": [
    "# Create data/{train,val,test}/{images,masks,distance_maps,label_masks,vague_masks}\n",
    "for split in SPLITS:\n",
    "    for sub in [\"images\", \"masks\", \"distance_maps\", \"label_masks\", \"vague_masks\"]:\n",
    "        (OUT_ROOT / split / sub).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Directory scaffold created under\", OUT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db846c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 665 complete data tuples across 31 organs.\n"
     ]
    }
   ],
   "source": [
    "# Collect tuples of paths: (tissue_img, mask_bin, distance_map, label_mask, vague_mask)\n",
    "data_tuples = []\n",
    "for organ in RAW_ROOT.iterdir():\n",
    "    if not organ.is_dir():\n",
    "        continue\n",
    "    # define per-organ subdirs\n",
    "    tissue_dir = organ / \"tissue images\"\n",
    "    mask_dir   = organ / \"mask binary\"\n",
    "    dist_dir   = organ / \"distance maps\"\n",
    "    label_dir  = organ / \"label masks modify\"\n",
    "    vague_dir  = organ / \"vague areas\" / \"mask binary\"\n",
    "\n",
    "    # check existence\n",
    "    for d in [tissue_dir, mask_dir, dist_dir, label_dir, vague_dir]:\n",
    "        if not d.exists():\n",
    "            print(f\"⚠️ Skipping {organ.name}: missing {d}\")\n",
    "            break\n",
    "    else:\n",
    "        # collect matching filenames by intersection\n",
    "        for img_path in tissue_dir.glob(\"*.png\"):\n",
    "            stem = img_path.stem\n",
    "            m1 = mask_dir / f\"{stem}.png\"\n",
    "            m2 = dist_dir / f\"{stem}.png\"\n",
    "            m3 = label_dir / f\"{stem}.tif\"\n",
    "            m4 = vague_dir / f\"{stem}.png\"\n",
    "            if m1.exists() and m2.exists() and m3.exists() and m4.exists():\n",
    "                data_tuples.append((img_path, m1, m2, m3, m4))\n",
    "            else:\n",
    "                print(f\"⚠️ Missing file for {stem} in {organ.name}\")\n",
    "\n",
    "print(f\"✅ Found {len(data_tuples)} complete data tuples across {len([d for d in RAW_ROOT.iterdir() if d.is_dir()])} organs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03729012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 531, Val: 67, Test: 67\n"
     ]
    }
   ],
   "source": [
    "# first separate test set\n",
    "train_val, test = train_test_split(\n",
    "    data_tuples, test_size=test_frac, random_state=random_seed\n",
    ")\n",
    "# then split train_val into train + val\n",
    "train, val = train_test_split(\n",
    "    train_val, test_size=val_frac/(1-test_frac), random_state=random_seed\n",
    ")\n",
    "print(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc04faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing & copying complete.\n"
     ]
    }
   ],
   "source": [
    "def process_and_save(split_list, split_name):\n",
    "    \"\"\"\n",
    "    Resizes each modality to TARGET_SIZE and saves into the split folders.\n",
    "    \"\"\"\n",
    "    for (img, msk, dist, lbl, vmask) in split_list:\n",
    "        # load all\n",
    "        arr_img  = cv2.imread(str(img))\n",
    "        arr_msk  = cv2.imread(str(msk),  cv2.IMREAD_GRAYSCALE)\n",
    "        arr_dist = cv2.imread(str(dist), cv2.IMREAD_GRAYSCALE)\n",
    "        arr_lbl  = cv2.imread(str(lbl),  cv2.IMREAD_UNCHANGED)\n",
    "        arr_v    = cv2.imread(str(vmask), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # resize to TARGET_SIZE\n",
    "        img_r  = cv2.resize(arr_img,  TARGET_SIZE, interpolation=cv2.INTER_CUBIC)\n",
    "        msk_r  = cv2.resize(arr_msk,  TARGET_SIZE, interpolation=cv2.INTER_NEAREST)\n",
    "        dist_r = cv2.resize(arr_dist, TARGET_SIZE, interpolation=cv2.INTER_NEAREST)\n",
    "        lbl_r  = cv2.resize(arr_lbl,  TARGET_SIZE, interpolation=cv2.INTER_NEAREST)\n",
    "        v_r    = cv2.resize(arr_v,    TARGET_SIZE, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # save\n",
    "        cv2.imwrite(str(OUT_ROOT/split_name/\"images\"/ img.name),  img_r)\n",
    "        cv2.imwrite(str(OUT_ROOT/split_name/\"masks\"/  msk.name),  msk_r)\n",
    "        cv2.imwrite(str(OUT_ROOT/split_name/\"distance_maps\"/ dist.name), dist_r)\n",
    "        cv2.imwrite(str(OUT_ROOT/split_name/\"label_masks\"/ lbl.name), lbl_r)\n",
    "        cv2.imwrite(str(OUT_ROOT/split_name/\"vague_masks\"/ vmask.name),  v_r)\n",
    "\n",
    "# run for each split\n",
    "process_and_save(train, \"train\")\n",
    "process_and_save(val,   \"val\")\n",
    "process_and_save(test,  \"test\")\n",
    "print(\"Resizing & copying complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82dce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  {'images': 531, 'masks': 531, 'distance_maps': 531, 'label_masks': 531, 'vague_masks': 531}\n",
      "val:  {'images': 67, 'masks': 67, 'distance_maps': 67, 'label_masks': 67, 'vague_masks': 67}\n",
      "test:  {'images': 67, 'masks': 67, 'distance_maps': 67, 'label_masks': 67, 'vague_masks': 67}\n"
     ]
    }
   ],
   "source": [
    "for split in SPLITS:\n",
    "    counts = {sub: len(list((OUT_ROOT/split/sub).glob(\"*.*\")))\n",
    "              for sub in [\"images\",\"masks\",\"distance_maps\",\"label_masks\",\"vague_masks\"]}\n",
    "    print(f\"{split}: \", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115cf4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
